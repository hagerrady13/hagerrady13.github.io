---
layout: archive
title: ""
permalink: /portfolio/
author_profile: true
---

## Projects

* **A real-time learning of an off-policy RL control algorithm on a real robot(Create2)** <br/>
This project applies reinforcement learning algorithms for robotics to learn in real-time. Using an off-policy policy gradient method, we trained an agent that learned how to move the Create2 robot to its docking station. In addition, we investigated the effect of changing one of the sub-goals on
the overall behaviour and how it potentially affects the learning process. Our approach outperforms the original implementation in the alignment sub-goal and makes the reward function more interpretable.  
Supervised by: Rupam A. Mahmood, RLAI Lab, University of Alberta. <br/>
[Report](https://drive.google.com/file/d/1QLVAHcYskx1Y2uVcXv51jGBDc08CDtV2/view?usp=sharing) - [Video](https://www.youtube.com/watch?v=ui3c8Tn-Fqc&feature=youtu.be) <br/>
A follow-up project presented at [RL4RealLife virtual conference](https://sites.google.com/view/RL4RealLife), you can find the presentation [here](https://www.youtube.com/watch?v=tlcAqwpxJUQ&feature=youtu.be)

* **An empirical analysis on policy-gradient methods vs. action-value based methods for control** <br/>
This project analyzes and compares action-value based methods vs. policy gradient methods, in a control problem. The project suggests that policy gradient methods should
learn faster than action-value based methods under function approximation. More specifically, one-step Sarsa is compared
with one-step actor-critic in the Mountain Car environment, where the empirical results were consistent with the original hypothesis.  <br/>
Project is part of the RLII course, taught by Richard Sutton in Winter 2020. [Report](https://drive.google.com/file/d/1Fb1SBwGZyZXVZk3X79Vh_N-MBvJs0lF6/view?usp=sharing) - [Code](https://github.com/hagerrady13/RLII-project)  


